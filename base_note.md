# NLP/LLM - Journey Base Note

## Base Resources
- [Stanford CS224 Website](https://web.stanford.edu/class/cs224n/)
- [Stanford CS224n YouTube](https://www.youtube.com/playlist?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4)
- [Stanford CS224n Assignments](https://github.com/amanchadha/stanford-cs224n-assignments-2021)
- [Karpathy's Zero to Hero](https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&si=9FmRYnBaGLTNrm1S)
- [Bulid LLM Form Scratch Book](https://www.manning.com/books/build-a-large-language-model-from-scratch/)
- [Annotated Research Paper Implementations](https://nn.labml.ai/)
- [Torchtune](https://pytorch.org/torchtune/main/index.html)
- [LLM Course](https://github.com/mlabonne/llm-course)

## Concepts to Learn
### Chapter1: Basics of NLP
1. [x] [Word Vectors](Chapter1/word2vec.md)
2. [x] [Word2Vec](Chapter1/word2vec.md)

### Chapter2: Neural Networks
3. [x] [Backpropagation and Neural Networks](Chapter2/backpropagation_nn.md)
4. [x] [Pytorch](Chapter2/pytorch.md)
5. [x] [Regularization & Activation Functions](Chapter2/regularization.md)

6. [x] [Make a Excalidraw file to dhow the pipeline of a Pytorch project and connect everything in this chapter](https://excalidraw.com/)
    - 

### Cahpter 3: Convolutional Layers & CNNs
7. [x] [Convolutional](Chapter3/convolutional.md)

### Chapter4: Recurrent Neural Networks & LSTMs
7. [x] [Recurrent Neural Networks](Chapter4/rnn.md)

### Chapter5: Seq2Seq, Attention and Transformers
6. [x] [Sequence to Sequence Models & Machine Translation](Chapter5/seq2seq.md)
7. [ ] [Attention Mechanism](Chapter5/attention.md)
### Chapter6:  Transformers
7. [ ] [Transformers](Chapter6/transformers.md)
#### Cahpter Project:

### Chapter7:  Large Language Models
8. [ ] [Large Language Models](Chapter7/llm.md)
    - Source: [LLM Course](https://github.com/mlabonne/llm-course)
    - Source: [LLM Traning](https://rentry.org/llm-training)

### Chapter99: Advanced Topics in LLMs
8. [ ] [Pretraining](Chapter4/pretraining.md)
9. [ ] [Post-training](Chapter4/posttraining.md)
    - [ ] Model Alignment (RLHF llm)
    - [ ] 
### Final Project Ideas
- Idea one: finetune BloombergGPT on Saudi Market, and use it to help in stock advice or to chat with the markt.
- Idea two: A library for a time series forecasting using Transformers.  
    - I will bulid it on top of `Pytorch`
    - Similar concept to Fastai's `timeseries` library.
- GUI for Nerual Network Design
    - The user will draw the layers and everything, and the app will generate the code for the user.

## Extra Concepts
- [ ] [Language Model Agents](Extra/lm_agents.md)
- [ ] [Multimodal Models](Extra/multimodal.md)